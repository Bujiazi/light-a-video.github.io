<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>AnimateDiff</title>
<link href="./DreamBooth_files/style.css" rel="stylesheet">
<script type="text/javascript" src="./DreamBooth_files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./DreamBooth_files/jquery.js"></script>

<style>
  p.serif{
    font-family:"Times New Roman", Times, serif;
  }
  p.sansserif{
    font-family: Arial, Helvetica, sans-serif;
  }
</style>
  
</head>

<body>
<div class="content">
  <h1><strong>AnimateDiff: Animate Personalized Image Diffusion Models via a Tuning-free Framework</strong></h1>
  <p id="authors" class="serif">
    <a href="mailto:guoyuwei@pjlab.org.cn">Yuwei Guo<sup>1,3</sup></a>
    <a href="https://ceyuan.me/">Ceyuan Yang<sup>1</sup></a>
    <a href="https://anyirao.com/">Anyi Rao<sup>4</sup></a>
    <a href="https://wyhsirius.github.io/">Yaohui Wang<sup>1</sup></a>
    <a href="http://mmlab.siat.ac.cn/yuqiao/index.html">Yu Qiao<sup>1</sup></a>
    <a href="http://dahua.site/">Dahua Lin<sup>1,2</sup></a>
    <a href="https://daibo.info/">Bo Dai<sup>1</sup></a>
    <br>
    <br>
    <a><sup>1</sup>Shanghai AI Laboratory</a>
    <a><sup>2</sup>The Chinese University of Hong Kong</a><br>
    <a><sup>3</sup>Nanjing University</a>
    <a><sup>4</sup>Stanford University</a>
  </p>

  <font size="+2">
    <p style="text-align: center;" class="serif">
      <a href="" target="_blank" style="font-weight: bold;">[Arxiv]</a> &nbsp;&nbsp;&nbsp;&nbsp;
      <a href="" target="_blank" style="font-weight: bold;">[Github repo]</a> &nbsp;&nbsp;&nbsp;&nbsp;
      <a href="" target="_blank" style="font-weight: bold;">[BibTeX]</a>
    </p><br>
  </font>

  <div class="row">
    <div class="col">
      <img src="figs/girl-blossom.gif" class="img-fluid example-img"><br>
      <!-- <p class="serif" style="text-align: center; margin: 5px;"><a href="">Model Link</a></p> -->
    </div>
    <div class="col"><img src="figs/castle.gif" class="img-fluid example-img"></div>
    <div class="col"><img src="figs/girl-closeup.gif" class="img-fluid example-img"></div>
  </div>

  <div class="row">
    <div class="col"><img src="figs/halo.gif" class="img-fluid example-img"></div>
    <div class="col"><img src="figs/squrriel.gif" class="img-fluid example-img"></div>
    <div class="col"><img src="figs/man-dark.gif" class="img-fluid example-img"></div>
  </div>

  <p style="text-align: left; font-size: 18px; margin: 10px;" class="serif">
    Generated with CivitAI models:
    <a href="https://civitai.com/models/30240/toonyou">ToonYou</a>
    <a href="https://civitai.com/models/22922/lyriel">Lyriel</a>
    <a href="https://civitai.com/models/43331/majicmix-realistic">majicMIX Realistic</a>
    <a href="https://civitai.com/models/66347/rcnz-cartoon-3d">RCNZ Cartoon 3d</a>
  </p>

</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Abstract</p>
  <p style="font-size: 1.2em" class="serif">Generating personalized animation clips is challenging due to the training costs and data collection. Existing text-to-video (T2V) generators are mostly trained with daily video like WebVid-10M and can only generate domain-specific animations with designed textual prompts. In this report, we take one step forward to the above target via solving a newly proposed problem setting, i.e., animating a text-to-image (T2I) model personalized for a specific domain, considering tuning a personalized image model is much cheaper than training in video domain. Our method first trains a motion modeling module inserted into the base T2I model with video data while freezing the original model weight unchanged. At inference time, the module is plugged into another personalized version of the base T2I model. Our key observations are: 1) T2I models are able to generate consistent content without updating their parameters; 2) tuning-based personalization methods scarcely modify the feature space of the base model, which ensures the generalizability of our pre-trained motion modeling module. Our extensive experiments demonstrate our method's effectiveness and its remarkable results.</p>
</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Pipeline</p>
  <p style="font-size: 1.2em" class="serif">Large text-to-image models achieved a remarkable leap in the evolution of AI, enabling high-quality and diverse synthesis of images from a given text prompt. However, these models lack the ability to mimic the appearance of subjects in a given reference set and synthesize novel renditions of them in different contexts.</p>
  <img class="summary-img" src="figs/framework.jpg" style="width:100%;"> <br>
  <p style="font-size: 1.2em" class="serif">Large text-to-image models achieved a remarkable leap in the evolution of AI, enabling high-quality and diverse synthesis of images from a given text prompt. However, these models lack the ability to mimic the appearance of subjects in a given reference set and synthesize novel renditions of them in different contexts. Large text-to-image models achieved a remarkable leap in the evolution of AI, enabling high-quality and diverse synthesis of images from a given text prompt. However, these models lack the ability to mimic the appearance of subjects in a given reference set and synthesize novel renditions of them in different contexts.</p>
</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Gallery</p>
  <p style="font-size: 1.2em" class="serif">Large text-to-image models achieved a remarkable leap in the evolution of AI, enabling high-quality and diverse synthesis of images from a given text prompt. However, these models lack the ability to mimic the appearance of subjects in a given reference set and synthesize novel renditions of them in different contexts.</p>

  <div class="row">
    <div class="col-gallery"><img src="figs/toonyou-01.gif" class="img-fluid example-img"><br></div>
    <div class="col-gallery"><img src="figs/toonyou-02.gif" class="img-fluid example-img"></div>
    <div class="col-gallery"><img src="figs/toonyou-03.gif" class="img-fluid example-img"></div>
    <div class="col-gallery"><img src="figs/toonyou-04.gif" class="img-fluid example-img"></div>
  </div>
  <p class="serif" style="font-size: 1.2em; text-align: left; margin: 5px; margin-bottom: 20px">Model: <a href="https://civitai.com/models/30240/toonyou">ToonYou</a></p>

  <div class="row">
    <div class="col-gallery"><img src="figs/counterfeit-01.gif" class="img-fluid example-img"><br></div>
    <div class="col-gallery"><img src="figs/counterfeit-02.gif" class="img-fluid example-img"></div>
    <div class="col-gallery"><img src="figs/counterfeit-03.gif" class="img-fluid example-img"></div>
    <div class="col-gallery"><img src="figs/counterfeit-04.gif" class="img-fluid example-img"></div>
  </div>
  <p class="serif" style="font-size: 1.2em; text-align: left; margin: 5px; margin-bottom: 20px">Model: <a href="https://civitai.com/models/4468/counterfeit-v30">Counterfeit V3.0</a></p>

  <div class="row">
    <div class="col-gallery"><img src="figs/realistic-02.gif" class="img-fluid example-img"><br></div>
    <div class="col-gallery"><img src="figs/realistic-01.gif" class="img-fluid example-img"></div>
    <div class="col-gallery"><img src="figs/realistic-03.gif" class="img-fluid example-img"></div>
    <div class="col-gallery"><img src="figs/realistic-04.gif" class="img-fluid example-img"></div>
  </div>
  <p class="serif" style="font-size: 1.2em; text-align: left; margin: 5px; margin-bottom: 20px">Model: <a href="https://civitai.com/models/4201/realistic-vision-v20">Realistic Vision V2.0</a></p>

  <div class="row">
    <div class="col-gallery"><img src="figs/portrait-01.gif" class="img-fluid example-img"><br></div>
    <div class="col-gallery"><img src="figs/portrait-02.gif" class="img-fluid example-img"></div>
    <div class="col-gallery"><img src="figs/portrait-05.gif" class="img-fluid example-img"></div>
    <div class="col-gallery"><img src="figs/portrait-04.gif" class="img-fluid example-img"></div>
  </div>
  <p class="serif" style="font-size: 1.2em; text-align: left; margin: 5px; margin-bottom: 20px">Model: <a href="https://civitai.com/models/43331/majicmix-realistic">majicMIX Realistic</a></p>

</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">BibTex</p>
  <!-- <code> @article{ruiz2022dreambooth,<br>
  &nbsp;&nbsp;title={DreamBooth: Fine Tuning Text-to-image Diffusion Models for Subject-Driven Generation},<br>
  &nbsp;&nbsp;author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},<br>
  &nbsp;&nbsp;booktitle={arXiv preprint arxiv:2208.12242},<br>
  &nbsp;&nbsp;year={2022}<br>
  } </code>  -->
</div>

<!-- <div class="content" id="acknowledgements">
  <p><strong>Acknowledgements</strong>:
    We thank Rinon Gal, Adi Zicher, Ron Mokady, Bill Freeman, Dilip Krishnan, Huiwen Chang and Daniel Cohen-Or for their valuable inputs that helped improve this work, and to Mohammad Norouzi, Chitwan Saharia and William Chan for providing us with their support and the pretrained models of Imagen. Finally, a special thank you to David Salesin for his feedback, advice and for his support for the project.
  </p>
</div> -->
</body>
</html>
